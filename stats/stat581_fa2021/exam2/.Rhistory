library("readxl")
#library("lme4")
library("lmerTest")
data = read_excel("exam2data.xlsx")
A = as.factor(na.omit(data$caliper)) # fixed effect
B = as.factor(na.omit(data$ball.bearing)) # random effect
y = na.omit(data$diameter) # response
head(data.frame(caliper=A,ball.bearing=B,diameter=y))
# fixed effect tau1 + tau2 + tau3 = 0 (for calipers)
contrasts(A)=contr.sum
random.mod = lmer(y ~ (1|B) + A)
# the anova command is used to compute the test for fixed effects.
anova(random.mod)
summary(random.mod)
str(summary(random.mod))
vcov(summary(random.mod))
sigma(summary(random.mod))
str(summary(random.mod))
sigma(summary(random.mod))
sigma2(summary(random.mod))
o=summary(random.mod)
sigma(o)
o
o$sigma
o$coefficients
o$residuals
mean(o$residuals^2)
o$vcov
o$sigma
o$varcor
o
o$varcor
sqrt(o$varcor)
o$varcor
o$varcor[1]
summary(random.mod)
VarCorr(summary(random.mod))
VarCorr(random.mod)
summary(random.mod)
VarCorr(random.mod)^2
xx
xx=VarCorr(random.mod)
xx$B
xx$B[1]
xx$B[2]
str(xx)
summary(random.mod)
VarCorr(random.mod,comp="Variance")
print(VarCorr(random.mod),comp="Variance")
print(round(VarCorr(random.mod),comp="Variance",digits=3))
print(round(VarCorr(random.mod),comp="Variance"),digits=3)
print(round(VarCorr(random.mod),comp="Variance"),digits=3))
print(round(VarCorr(random.mod),comp="Variance"),digits=3)
VarCorr(random.mod,comp="Variance")
print(VarCorr(random.mod),comp="Variance")
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
estimates = summary(random.mod)
estimates.tau.hat = c(estimates$coefficients[1:4,1],0-sum(estimates$coefficients[2:4,1]))
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
estimates = summary(random.mod)
estimates
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
estimates = coef(summary(random.mod))
estimates
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
estimates.tau.hat = coef(random.mod)
estimates.hat.hat
estimates.hat
estimates.tau.hat
estimates.tau.hat = c(estimates[1:4,1],0-sum(estimates[2:4,1]))
str(estimates)
estimates[1]
estimates[1:4]
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
random.mod
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
summary(random.mod)
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
coef(summary(random.mod))
summary(random.mod)
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
coef(summary(random.mod))
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
est = coef(summary(random.mod))
str(est)
str
est
est[1,1]
est[1:3]
estimates[1:4,1]
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
est = coef(summary(random.mod))
est[1:3]
est[1:3,1]
est.tau.hat = c(estimates[1:3,1],0-sum(estimates[2:3,1]))
names(estimates.tau.hat) = c("mu","tau1","tau2","tau3")
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
est = coef(summary(random.mod))
est.tau.hat = c(est[1:3,1],0-sum(est[2:3,1]))
names(est.tau.hat) = c("mu","tau1","tau2","tau3")
est.tau.hat
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
est = coef(summary(random.mod))[1]
est
# since the fixed effect estimates must sum to 0, the estimate at level a=4 is
# the negative of the sum of the fixed effect estimates at levels 1 through a-1.
est = coef(summary(random.mod))[1:3,1]
est
est.tau.hat = c(est,0-sum(est[2:3]))
names(est.tau.hat) = c("mu","tau1","tau2","tau3")
est.tau.hat
est.tau.hat
round(est.tau.hat,digits=3)
A = as.factor(na.omit(data$device)) # fixed effect
B = as.factor(na.omit(data$ball)) # random effect
y = na.omit(data$measurement) # response
head(data.frame(caliper=A,ball=B,measurement=y))
data.frame(caliper=A,ball=B,measurement=y)
interaction.plot(B,A,y)
mixed.mod = lmer(y ~ A + (1|B) + (1|A:B))
mixed.mod
anova(mixed.mod)
mixed.test(A,B,y)
t = mixed.test(A,B,y)
mixed.test = function(A,B,y)
{
av=anova(lm(y~A*B))
F.a = av$`Mean Sq`[1]/av$`Mean Sq`[3]
p.value = pf(F.a,df1=av$Df[1],df2=av$Df[3],lower.tail = FALSE)
table1 = matrix(c(av$`Sum Sq`[1],av$`Sum Sq`[2],av$`Sum Sq`[3],av$`Sum Sq`[4],
av$Df[1],av$Df[2],av$Df[3],av$Df[4],
av$`Mean Sq`[1],av$`Mean Sq`[2],av$`Mean Sq`[3],av$`Mean Sq`[4]),nrow = 4)
dimnames(table1) = list(c("Fixed Effect A","Random Effect B","Interaction AB","Error"),
c("SS","df","MS"))
print(table1)
table2 = matrix(c(F.a,p.value),nrow = 1)
dimnames(table2) = list(c(""),c("F-test for fixed effect","p-value"))
print(table2)
a=nlevels(A)
b=nlevels(B)
n=length(y) / a / b
var.hat = av$`Mean Sq`[4]
var.interaction.hat = (av$`Mean Sq`[3]-av$`Mean Sq`[4])/n
var.block = (av$`Mean Sq`[2]-av$`Mean Sq`[3])/n/a
table3 = matrix(c(var.hat,var.interaction.hat,var.block),nrow=1)
dimnames(table3) = list(c(""),c("error.var","interaction.var","block.var"))
print(table3)
}
t = mixed.test(A,B,y)
str(t)
t[1,1]
t[1,2]
t[1,3]
t[1,2]
mixed.test(A,B,y)
prom = na.omit(as.factor(data$promotion))
presales = na.omit(data$presales)
sales = na.omit(data$sales)
ancova.mod = lm(sales ~ presales + prom)
ancova.mod
summary(ancova.mod)
#We begin by calling the data for handout 11
library("readxl")
h11.data = read_excel("handout11data.xlsx")
h11.data = read_excel("../stat581_fa2021/hw/hw11/handout11data.xlsx")
str(h11.data)
#We will use the package lsmeans for computing least squares means in Analysis of Covariance
library("lsmeans")
#We will use the package car (companion to applied regression) for computing partial sums of squares
library("car")
#Example 11.1
#Data is collected to investigate the effect of origin on the weight of a turkey, with age used as a covariate.
origin = as.factor(na.omit(h11.data$origin))
age = na.omit(h11.data$age)
weight = na.omit(h11.data$weight)
#We fit an ANCOVA model using the following code. lm is an abbreviation for linear model.
ancova.mod = lm(weight ~ age + origin)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
summary(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
summary(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
summary(ancova.mod)
#Example 11.1
#Data is collected to investigate the effect of origin on the weight of a turkey, with age used as a covariate.
machine = as.factor(na.omit(h11.data$machine))
diameter = na.omit(h11.data$diameter)
strength = na.omit(h11.data$strength)
#We fit an ANCOVA model using the following code. lm is an abbreviation for linear model.
ancova.mod = lm(strength ~ diameter + machine)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
summary(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
anova(ancova.mod)
prom = na.omit(as.factor(data$promotion))
presales = na.omit(data$presales)
sales = na.omit(data$sales)
ancova.mod = lm(sales ~ presales + prom)
anova(ancova.mod)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(ancova.mod)
######## 1(c)
# We fit an ANCOVA model using the following code. lm is an abbreviation for linear model.
#         R(A|x)/(a-1)
# F_A|x = ----------------
#         SSE(A,x)/(N-a-1)
hw1.ancova.mod = lm(strength ~ diameter + machine)
######## 1(c)
# We fit an ANCOVA model using the following code. lm is an abbreviation for linear model.
#         R(A|x)/(a-1)
# F_A|x = ----------------
#         SSE(A,x)/(N-a-1)
hw11.ancova.mod = lm(strength ~ diameter + machine)
#The anova command creates a table with sequential sums of squares.
#The summary command displays the parameter estimates.
anova(hw11.ancova.mod)
prom = na.omit(as.factor(data$promotion))
presales = na.omit(data$presales)
sales = na.omit(data$sales)
ancova.mod = lm(sales ~ presales + prom)
summary(ancova.mod)
anova(ancova.mod)
#The summary command displays the parameter estimates.
summary(hw11.ancova.mod)
#The default parameterization in R does not match that from our notes.
#Use the following commands to compute the intercepts and slope for each regression function.
#We will least squares means later to complete the re-parameterization
a.intercept.g = coef(hw11.ancova.mod)[1]
a.intercept.v = coef(hw11.ancova.mod)[1]+coef(hw11.ancova.mod)[3]
a.intercept.w = coef(hw11.ancova.mod)[1]+coef(hw11.ancova.mod)[4]
a.slope = coef(hw11.ancova.mod)[2]
#The default parameterization in R does not match that from our notes.
#Use the following commands to compute the intercepts and slope for each regression function.
#We will least squares means later to complete the re-parameterization
a.intercept.g = coef(hw11.ancova.mod)[1]
a.intercept.v = coef(hw11.ancova.mod)[1]+coef(hw11.ancova.mod)[3]
a.intercept.w = coef(hw11.ancova.mod)[1]+coef(hw11.ancova.mod)[4]
a.slope = coef(hw11.ancova.mod)[2]
#The following code creates a display of the regression line estimates
a.intercepts = c(a.intercept.g,a.intercept.v,a.intercept.w)
a.slopes = c(a.slope,a.slope,a.slope)
a.intercepts
means.table
library("lsmeans")
library("car")
xbar.prom = aggregate(presales, by=list(prom), FUN=mean)
ybar.prom = aggregate(sales, by=list(prom), FUN=mean)[2]
means.table = cbind(xbar.prom,ybar.prom)
colnames(means.table) = c("prom","presales.mean","sales.mean")
means.table
#The overall mean for the covariate age will determine the adjustment to the response sample means
mean(presales)
means.table
# compute least squares means and
# perform pairwise comparisons on the adjusted means.
#lsmeans(ancova.mod,pairwise ~ prom,adjust="none")
lsmeans(ancova.mod,adjust="none")
?lsmeans
?lsmeans
# compute least squares means and
# perform pairwise comparisons on the adjusted means.
#lsmeans(ancova.mod,pairwise ~ prom,adjust="none")
lsmeans(ancova.mod,NULL,adjust="none")
?lsmeans
# compute least squares means and
# perform pairwise comparisons on the adjusted means.
x = lsmeans(ancova.mod,pairwise ~ prom,adjust="none")
x$lsmeans
