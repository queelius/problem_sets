
@misc{bias_variance,
	title = {Bias–variance tradeoff},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Bias%E2%80%93variance_tradeoff&oldid=1018809373},
	abstract = {In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.
The bias–variance dilemma or bias–variance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:
The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).
The variance is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting).The bias–variance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself.},
	language = {en},
	urldate = {2021-04-27},
	journal = {Wikipedia},
	month = apr,
	year = {2021},
	note = {Page Version ID: 1018809373},
	file = {Snapshot:/home/spinoza/Zotero/storage/NIXJA3HP/index.html:text/html},
}

@misc{rob_arimax_nodate,
	title = {The {ARIMAX} model muddle},
	url = {https://robjhyndman.com/hyndsight/arimax/},
	urldate = {2021-04-27},
	author = {Rob, Hundman},
	file = {The ARIMAX model muddle | Rob J Hyndman:/home/spinoza/Zotero/storage/AMY29JGC/arimax.html:text/html},
}

@misc{noauthor_dickeyfuller_2021,
	title = {Dickey–{Fuller} test},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Dickey%E2%80%93Fuller_test&oldid=1019701572},
	abstract = {In statistics, the Dickey–Fuller test tests the null hypothesis that a unit root is present in an autoregressive model. The alternative hypothesis is different depending on which version of the test is used, but is usually stationarity or trend-stationarity. It is named after the statisticians David Dickey and Wayne Fuller, who developed the test in 1979.},
	language = {en},
	urldate = {2021-04-28},
	journal = {Wikipedia},
	month = apr,
	year = {2021},
	note = {Page Version ID: 1019701572},
	file = {Snapshot:/home/spinoza/Zotero/storage/FJPCQIGE/index.html:text/html},
}

@misc{noauthor_gaussmarkov_2021,
	title = {Gauss–{Markov} theorem},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Gauss%E2%80%93Markov_theorem&oldid=1014393295},
	language = {en},
	urldate = {2021-04-30},
	journal = {Wikipedia},
	month = mar,
	year = {2021},
	note = {Page Version ID: 1014393295},
}
