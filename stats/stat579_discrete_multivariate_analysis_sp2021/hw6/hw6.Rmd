---
title: 'Discrete Multivariate Analysis - 579 - HW #6'
author: "Alex Towell (atowell@siue.edu)"
header-includes:
 - \usepackage{amsmath}
 - \usepackage{mathtools}
 - \usepackage{amsthm}
 - \usepackage{multirow}
 - \usepackage{booktabs}
output:
  pdf_document:
    df_print: kable
  html_document:
    df_print: paged
---

\newcommand{\var}{\operatorname{Var}}
\newcommand{\expect}{\operatorname{E}}
\newcommand{\corr}{\operatorname{Corr}}
\newcommand{\cov}{\operatorname{Cov}}
\newcommand{\ssr}{\operatorname{SSR}}
\newcommand{\se}{\operatorname{SE}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\RR}{\operatorname{RR}}
\newcommand{\eval}[2]{\left. #1 \right\vert_{#2}}

# Problem 1
\fbox{
\begin{minipage}{.8\textwidth}
Suppose $n_1 \sim \rm{BIN}(n,\pi)$. Then, $\hat\pi = n_1/n$ has an asymptotic
normal distribution $\mathcal{N}(\pi,\pi(1-\pi)/n)$. Use the delta method
to determine $\sigma^2 \log(\hat\pi/(1-\hat\pi))$, the asymptotic variance
of the sample log odds.
\end{minipage}
}

If we have a non-linear function of some random variable,
in the delta method we use a Taylor approximation of the function centered around
the random variables expected value such that the approximate variance of the
function of the random variable is easily computed.

Let $\operatorname{g}(\hat\pi) = \log(\hat\pi/(1-\hat\pi))$.
A linear approximation of $\operatorname{g}$ is given by
$$
  \operatorname{\hat g}(\hat\pi) = \operatorname{g}(\pi) +\operatorname{g'}(\pi)(\hat\pi - \pi),
$$
the derivative of $\operatorname{g}$ is given by
$$
  \operatorname{g'}(\pi) = \frac{1}{\pi(1-\pi)},
$$
and the variance of $\operatorname{\hat g}(\hat\pi)$ is given by
\begin{align*}
  \var(\operatorname{\hat g}(\hat \pi))
    &= \left(\operatorname{g'}(\pi)\right)^2 \var(\hat\pi)\\
    &= \frac{1}{\pi^2(1-\pi)^2} \frac{\pi(1-\pi)}{n}\\
    &= \frac{1}{\pi(1-\pi)} \frac{1}{n}.
\end{align*}

Since we do not know $\pi$, we approximate it with $\hat\pi$, thus
$$
  \sigma^2(\log(\hat\pi/(1-\hat\pi))) = \frac{1}{\hat\pi(1-\hat\pi)} \frac{1}{n}.
$$
# Problem 2

Consider data from a retrospective study on the relationship between daily
alcohol consumption and the onset of esophagus cancer.

\begin{table}[h]
\centering
\begin{tabular}{@{}rrrr@{}}
\toprule
                                            &           & cancer&no cancer\\
\cmidrule{3-4}
\multirow{2}{*}{daily alcohol consumption}  & $> 80$g  	& 71    & 82\\
                                            & $< 80$g 	& 60    & 441\\
                                            & total     & 131   & 523\\
\bottomrule
\end{tabular}
\end{table}

## Part (a)
\fbox{Provide an equation for $\hat\sigma(\log \hat\theta)$.}

In a retrospective study, the table draws samples from the conditional probabilities
$\operatorname{P}(X = i | Y = j)$ and we denote $\operatorname{P}(X = 1 | Y = j)$
by $p_j$.

The ML estimator of $p_j$ from the data in a retrospective study is given by
$$
  \hat p_j = \frac{n_{1 j}}{n_{+j}}.
$$

In a retrospective study, an estimator of $\sigma(\log \hat\theta)$ is given by
$$
  \hat\sigma(\log \hat\theta) = \left[
    \left(\frac{1}{\hat{p}_1} + \frac{1}{1-\hat{p}_1}\right)\frac{1}{n_{+1}} +
    \left(\frac{1}{\hat{p}_2} + \frac{1}{1-\hat{p}_2}\right)\frac{1}{n_{+2}} +
    \right]^{1/2}.
$$

## Part (b)
\fbox{Does your answer in (a) depend on the sampling scheme? Explain.}

It does not depend on the sampling scheme.
When asymptotic normality holds, replacing parameters with statistics invokes
the likelihood principle.

When we substitute the MLE $\hat p_j$ into the equation for
$\hat \sigma(\log \hat \theta)$, we get the result
$$
  \hat\sigma(\log \hat\theta) = \left(\frac{1}{n_{1 1}} + \frac{1}{n_{2 1}} + \frac{1}{n_{1 2}} + \frac{1}{n_{2 2}} \right)^{1/2},
$$
which is the same as for retrospective studies and cross-sectional studies.

## Part (c)
\fbox{Compute a $95\%$ confidence interval for $\log \theta$.}

Recall $\theta = \frac{p_1 / (1 - p_1)}{p_2 / (1 - p_2)}$.
If we replace $p_j$ by its ML estimator $\hat p_j$, then
$$
  \hat p_1 = \frac{n_{1 1}}{n_{+1}} = \frac{71}{131} \approx 0.542
$$
and
$$
  \hat p_2 = \frac{n_{1 2}}{n_{+2}} = \frac{82}{523} \approx 0.157.
$$
Thus, by the invariance property of MLEs,
$$
  \hat\theta = \frac{\hat p_1 / (1 - \hat p_1)}{\hat p_2 / (1 - \hat p_2)} \approx \frac{0.542 / 0.458}{0.157 / 0.843} \approx 6.354
$$
and therefore $\log \theta \approx \log 6.354 \approx 1.850$.
Next, we need to find the standard deviation of the $\log \hat\theta$,
$$
  \hat\sigma(\log \hat\theta) = \left[
    \left(\frac{1}{0.542} + \frac{1}{0.458}\right)\frac{1}{131} +
    \left(\frac{1}{0.157} + \frac{1}{0.843}\right)\frac{1}{523}
    \right]^{1/2} \approx 0.213.
$$

Thus, a $95\%$ confidence interval for $\log \theta$ is
$$
  \log \hat \theta \pm 1.96 \hat\sigma(\log \hat \theta).
$$
Plugging in these computed values, we get the $95\%$ confidence interval
$$
  [1.850 - 0.417,1.850 + 0.417] = [1.433,2.267].
$$

## Part (d)
\fbox{
\begin{minipage}{.8\textwidth}
Compute $\hat\gamma$ for the $2\times 2$ table.
Provide an interpretation of the effect size, stated in the context of the problem.
\end{minipage}
}

Observe that
$$
  \hat\gamma = \frac{\hat\theta-1}{\hat\theta+1}.
$$
The MLE $\hat\theta \approx 6.354$. Thus, $\hat\gamma \approx \frac{6.354-1}{6.354+1} \approx 0.728$.

We estimate that there is a \emph{large} size, positive association between
daily alcohol consumption and the onset of cancer.

# Problem 3

For the \emph{counts} array, we populated it with the values
$(7,7,2,3,2,8,3,7,1,5,4,9,2,8,9,14)$ and ran the code.

```{r echo=FALSE}
#below is a program for computing a Bayesian / likelihood interval estimate for gamma
#you will need install.packages("dirmult") in order to simulate probs from a Dirichlet distribution
library(dirmult)

#enter the row dimension and column dimension
dimR = 4
dimC = 4

#enter the observed cross-sectional data, by row
counts = c(7,7,2,3,2,8,3,7,1,5,4,9,2,8,9,14)

#define parameters for the Dirichlet distribution
dir.post = counts+1

#simulate probs, then compute gamma for each simulation
simN = 10000
gamma = rep(NA,simN)
sim = 1
for (sim in 1:simN){
  p = rdirichlet(1,dir.post)
  probs = matrix(p,nrow = dimR,byrow = TRUE)
  
  con = 0
  i=1
  j=1
  for (i in 1:(dimR-1)) {
    for (j in 1:(dimC-1)) {
      sub = 0
      h=i+1
      while (h <= dimR) {
        k=j+1
        while (k <= dimC) {
          sub = sub + probs[h,k]
          k=k+1
        }
        h=h+1
      }
      con = con + probs[i,j]*sub
      j=j+1
    }
    i=i+1
  }
  
  
  dis = 0
  i=1
  j=1
  for (i in 1:(dimR-1)) {
    for (j in 2:dimC) {
      sub = 0
      h=i+1
      while (h <= dimR) {
        k=j-1
        while (k >= 1) {
          sub = sub + probs[h,k]
          k=k-1
        }
        h=h+1
      }
      dis = dis + probs[i,j]*sub
      j=j+1
    }
    i=i+1
  }
  
  gamma[sim] = (con-dis)/(con+dis)
  
  sim = sim+1
}

#plot and summarize the data evidence regarding the gamma correlation
#hist(gamma,probability = TRUE)
#points(density(gamma),type = 'l')

quantile(gamma,c(.025,.25,.5,.75,.975))
```

Thus, a $95\%$ interval estimate is approximately $[0.1,0.5]$.


